# 自己动手些网络爬虫 #

----------
## 第 1 篇  自己动手抓取数据 ##

**第 1 章 全面剖析网络爬虫** 

> 
你知道百度、Google 是如何获取数以亿计的网页并且实时更新的吗？你知道在搜索引 擎领域人们常说的 Spider 是什么吗？本章将全面介绍网络爬虫的方方面面。读完之后，你 将完全有能力自己写一个网络爬虫，随意抓取互联网上任何感兴趣的东西。 既然百度、Google 这些搜索引擎巨头已经帮我们抓取了互联网上的大部分信息，为什 么还要自己写爬虫呢？因为深入整合信息的需求是广泛存在的。在企业中，爬虫抓取下来 的信息可以作为数据仓库多维展现的数据源，也可以作为数据挖掘的来源。甚至有人为了 炒股，专门抓取股票信息。既然从美国中情局到普通老百姓都需要，那还等什么，让我们

----------

- HTTP 状态码
> HTTP 状态码表示 HTTP 协议所返回的响应的状态。比如客户端向服务器发送请求，如 果成功地获得请求的资源，则返回的状态码为 200，表示响应成功。如果请求的资源不存在， 则通常返回 404 错误。 HTTP 状态码通常分为 5 种类型，分别以 1～5 五个数字开头，由 3 位整数组成。1XX 通常用作实验用途。这一节主要介绍 2XX、3XX、4XX、5XX 等常用的几种状态码，如 表 1.1 所示。

![](https://i.imgur.com/V7GH7ui.png)


![](https://i.imgur.com/qRL5Tuy.png)

----------


- 爬虫队列
  
> 爬虫队列的设计是网络爬虫的关键。爬虫队列是用来保存 URL 的队列数据结构的。在 大型爬虫应用中，构建通用的、可以扩缩的爬虫队列非常重要。数以十亿计的 URL 地址， 使用内存的链表或者队列来存储显然不够，
> 因此，需要找到一种数据结构，这种数据结构 具有以下几个特点：
>     1、能够存储海量数据，当数据超出内存限制的时候，能够把它固化在硬盘上。
>     2、存取数据速度非常快。
>     3、能够支持多线程访问(多线程技术能够大规模提升爬虫的性能，这点将在之后 的章节详细介绍)。
> 结合上面 3 点中对存储速度的要求，使 Hash 成为存储结构的不二选择。 通常，在进行 Hash 存储的时候，
> key 值都选取 URL 字符串，但是为了更节省空间，通 常会对 URL 进行压缩。常用的压缩算法是 MD5 压缩算法。

----------

- Berkeley DB 构建爬虫队列

> Berkeley DB 是一个嵌入式数据库，它适合于管理海量的、简单的数据。例如，Google 用 Berkeley DB HA (High Availability)来管理他们的账户信息。Motorola 在它的无线产品中 用 Berkeley DB 跟踪移动单元。HP、Microsoft、Sun Microsystems 等也都是它的大客户。 Berkeley DB 不能完全取代关系型数据库，但在某些方面，它却令关系数据库望尘莫及。 关键字/数据(key/value)是 Berkeley DB 用来进行数据库管理的基础。每个 key/value 对 构成一条记录。而整个数据库实际上就是由许多这样的结构单元所构成的。通过这种方式， 开发人员在使用 Berkeley DB 提供的 API 访问数据库时，只需提供关键字就能够访问到相应 的数据。当然也可以提供 Key 和部分 Data 来查询符合条件的相近数据。 Berkeley DB 底层实现采用 B 树，可以看成能够存储大量数据的 HashMap。Berkeley

----------

- 布隆过滤器构建 Visited 表

> 布隆过滤器绝对不会漏掉任何一个在黑名单中的可疑地址。但是，它有一条不足之处。 也就是它有极小的可能将一个不在黑名单中的电子邮件地址判定为在黑名单中，因为有可 能某个好的邮件地址正巧对应 8 个都被设置成 1 的二进制位。好在这种可能性很小。我们 把它称为误识概率。在上面的例子中，误识概率大概在万分之一以下。常见的补救办法是 建立一个小的白名单，存储那些可能误判的邮件地址。

![](https://i.imgur.com/dl4nm7I.png)

> 为每个 URL 分配两个字节就可以达到千分之几的冲突。比较保守的实现是，为每 个 URL 分配 4 个字节，项目和位数比是 1∶32，误判率是 0.00000021167340。对于 5000 万数 量级的 URL，布隆过滤器只占用 200MB 的空间，并且排重速度超快，一遍下来不到两分钟。

----------


- 设计爬虫架构

> 一个设计良好的爬虫架构必须满足如下需求。
>  (1) 分布式：爬虫应该能够在多台机器上分布执行。
>  (2) 可伸缩性：爬虫结构应该能够通过增加额外的机器和带宽来提高抓取速度。
>  (3) 性能和有效性：爬虫系统必须有效地使用各种系统资源，例如，处理器、存储空 间和网络带宽。
>  (4) 质量：鉴于互联网的发展速度，大部分网页都不可能及时出现在用户查询中，所 以爬虫应该首先抓取有用的网页。
>  (5) 新鲜性：在许多应用中，爬虫应该持续运行而不是只遍历一次。
>  (6) 更新：因为网页会经常更新，例如论坛网站会经常有回帖。爬虫应该取得已经获 取的页面的新的拷贝。例如一个搜索引擎爬虫要能够保证全文索引中包含每个索引页面的 较新的状态。对于搜索引擎爬虫这样连续的抓取，爬虫访问一个页面的频率应该和这个网 页的更新频率一致。
>  (7) 可扩展性：为了能够支持新的数据格式和新的抓取协议，爬虫架构应该设计成模 块化的形式。

![](https://i.imgur.com/j0hTL3k.png)
> 这里最主要的关注对象是爬虫和存储库。其中的爬虫部分阶段性地抓取互联网上的内 容。存储库存储爬虫下载下来的网页，是分布式的和可扩展的存储系统。在往存储库中加 载新的内容时仍然可以读取存储库。 实际的爬虫逻辑架构如图 1.10 所示。
> 
> 其中： 
> (1) URL Frontier 包含爬虫当前待抓取的 URL(对于持续更新抓取的爬虫，以前已经抓 取过的 URL 可能会回到 Frontier 重抓)。 
> (2) DNS 解析模块根据给定的 URL 决定从哪个 Web 服务器获取网页。
> (3) 获取模块使用 HTTP 协议获取 URL 代表的页面。 
> (4) 解析模块提取文本和网页的链接集合。 
> (5) 重复消除模块决定一个解析出来的链接是否已经在 URL Frontier 或者最近下载过。

![](https://i.imgur.com/yduXC4m.png)

----------

